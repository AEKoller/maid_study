{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running integration test with query: 'Assisted+dying', max articles: 5, model: llama3\n",
      "Total articles found: 3878\n",
      "Fetching up to 5 articles...\n",
      "Successfully fetched 5 articles.\n",
      "Articles before processing:\n",
      "ID: 39167528, Title: The Impact of Legalizing Medical Aid in Dying on P...\n",
      "Warning: Article 39167528 has no abstract.\n",
      "ID: 39160544, Title: Non-invasive technology to assess hydration status...\n",
      "ID: 39157533, Title: Readiness of nurses when faced with a patient's de...\n",
      "ID: 39157418, Title: 'There is no such word as palliative care for us a...\n",
      "ID: 39152645, Title: The double awareness of the wish to hasten death a...\n",
      "\n",
      "Processing article 1 of 5...\n",
      "Article ID: 39167528\n",
      "DOI: 10.1089/jpm.2023.0706\n",
      "Title: The Impact of Legalizing Medical Aid in Dying on Patient Trust: A Randomized Controlled Survey Study.\n",
      "Abstract: Abstract not available...\n",
      "Study Type: Empirical\n",
      "Study Type Justification: The study is empirical because it aims to investigate and measure the impact of legalizing medical aid in dying on patient trust through a randomized controlled survey study. The researchers are collecting data from patients who have experienced the legal change, which allows for quantifiable results.\n",
      "Research Methods: Survey, Randomized Controlled Trial\n",
      "Research Methods Justification: The researchers used a survey to collect self-reported data from participants and implemented a randomized controlled trial design to ensure that the participants were randomly assigned to either an experimental or control group. This allows for statistical comparisons between the two groups, providing more reliable results.\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing article 2 of 5...\n",
      "Article ID: 39160544\n",
      "DOI: 10.1186/s12904-024-01542-z\n",
      "Title: Non-invasive technology to assess hydration status in advanced cancer to explore relationships between fluid status and symptoms: an observational study using bioelectrical impedance analysis.\n",
      "Abstract: Oral fluid intake decreases in advanced cancer in the dying phase of illness. There is inadequate ev...\n",
      "Study Type: Empirical\n",
      "Study Type Justification: The study aims to explore relationships between fluid status and symptoms in advanced cancer patients, using a non-invasive technology called bioelectrical impedance analysis (BIA). This empirical study involves collecting data through measurement or observation, rather than relying on existing knowledge or theoretical frameworks.\n",
      "Research Methods: Content Analysis, Secondary Data Analysis, Bioelectrical Impedance Analysis, Secondary Analysis\n",
      "Research Methods Justification: The use of BIA as the primary research method is justified because it allows for a non-invasive assessment of hydration status in advanced cancer patients. This method has potential to inform clinical management by examining relationships between fluid status and clinical variables, which is the study's main objective.\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing article 3 of 5...\n",
      "Article ID: 39157533\n",
      "DOI: 10.3389/fpubh.2024.1399025\n",
      "Title: Readiness of nurses when faced with a patient's death.\n",
      "Abstract: The death of a patient negatively affects the professional dimension of nurses' functioning and also...\n",
      "Study Type: Theoretical\n",
      "Study Type Justification: This study appears to be theoretical in nature as it does not aim to collect empirical data or test specific hypotheses. Instead, the article focuses on discussing the emotional and professional impacts of patient death on nurses, which is a more conceptual and exploratory approach.\n",
      "Research Methods: Unable to determine\n",
      "Research Methods Justification: The abstract does not mention any specific research methods used in this study. Since it's classified as theoretical, it's likely that the authors relied on existing literature and conceptual frameworks to support their arguments rather than conducting empirical research.\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing article 4 of 5...\n",
      "Article ID: 39157418\n",
      "DOI: 10.1177/26323524241272102\n",
      "Title: 'There is no such word as palliative care for us at the moment': A mixed-method study exploring the perceptions of healthcare professionals on the need for palliative care in Bhutan.\n",
      "Abstract: The need for palliative care is ever-increasing globally. However, it is least developed or not avai...\n",
      "Study Type: Empirical\n",
      "Study Type Justification: The study is empirical because it involves collecting primary data from healthcare professionals in Bhutan through mixed-methods approaches, including surveys and interviews. The study aims to explore perceptions on the need for palliative care, which is a specific phenomenon that can be studied using empirical methods.\n",
      "Research Methods: Survey, Interview\n",
      "Research Methods Justification: The researchers used a mixed-methods approach, combining both quantitative (surveys) and qualitative (interviews) methods. This allowed them to gather both numerical data on the perceptions of healthcare professionals and in-depth insights into their experiences and views on palliative care.\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing article 5 of 5...\n",
      "Article ID: 39152645\n",
      "DOI: 10.1177/02692163241269689\n",
      "Title: The double awareness of the wish to hasten death and the will to live: A secondary analysis of outlier patients from a mixed-methods study.\n",
      "Abstract: Patients with serious illness frequently report (temporary) wishes to hasten death. Even until the e...\n",
      "Study Type: Empirical\n",
      "Study Type Justification: The study is empirical because it involves collecting and analyzing data from patients with serious illness, which is a real-world phenomenon. The researchers conducted a secondary analysis of outlier patients from a mixed-methods study, suggesting that they collected primary data using a combination of methods (e.g., surveys, interviews) before conducting this secondary analysis.\n",
      "Research Methods: Case Study, Cohort Study, Cross-sectional Study, Longitudinal Study, Mixed Methods, Content Analysis, Secondary Data Analysis, Bioelectrical Impedance Analysis, Observational Study, Secondary Analysis, Mixed-method Study\n",
      "Research Methods Justification: The use of a mixed-methods approach allows the researchers to collect both quantitative and qualitative data from patients with serious illness. This is important because it provides a comprehensive understanding of the complex relationship between the wish to hasten death and the will to live. The secondary analysis of outlier patients suggests that the researchers identified a subset of patients who exhibited unusual or extreme responses, which they then analyzed further to gain insights into their experiences.\n",
      "--------------------------------------------------\n",
      "\n",
      "Integration test complete! Processed 5 articles.\n",
      "Results saved to pubmed_ollama_test_results_20240821_195713.json\n",
      "Results saved to pubmed_ollama_test_results_20240821_195713.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import re\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "\n",
    "STANDARD_METHODS = [\n",
    "    \"Survey\", \"Interview\", \"Questionnaire\", \"Observation\", \"Experiment\",\n",
    "    \"Case Study\", \"Literature Review\", \"Meta-analysis\", \"Randomized Controlled Trial\",\n",
    "    \"Cohort Study\", \"Cross-sectional Study\", \"Longitudinal Study\", \"Mixed Methods\",\n",
    "    \"Focus Group\", \"Ethnography\", \"Grounded Theory\", \"Phenomenology\", \"Content Analysis\",\n",
    "    \"Secondary Data Analysis\", \"Bioelectrical Impedance Analysis\", \"Observational Study\",\n",
    "    \"Secondary Analysis\", \"Mixed-method Study\"\n",
    "]\n",
    "\n",
    "def normalize_research_methods(methods_string):\n",
    "    normalized_methods = []\n",
    "    for method in STANDARD_METHODS:\n",
    "        if any(word.lower() in methods_string.lower() for word in method.split()):\n",
    "            normalized_methods.append(method)\n",
    "    return \", \".join(normalized_methods) if normalized_methods else \"Unable to determine\"\n",
    "\n",
    "def fetch_pubmed_articles(query, max_results=5):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    \n",
    "    search_url = f\"{base_url}esearch.fcgi?db=pubmed&term={query}&usehistory=y&retmode=json\"\n",
    "    search_response = requests.get(search_url).json()\n",
    "    \n",
    "    total_count = int(search_response['esearchresult']['count'])\n",
    "    webenv = search_response['esearchresult']['webenv']\n",
    "    query_key = search_response['esearchresult']['querykey']\n",
    "    \n",
    "    print(f\"Total articles found: {total_count}\")\n",
    "    print(f\"Fetching up to {max_results} articles...\")\n",
    "\n",
    "    fetch_url = f\"{base_url}efetch.fcgi?db=pubmed&query_key={query_key}&WebEnv={webenv}&retmode=xml&retmax={max_results}\"\n",
    "    fetch_response = requests.get(fetch_url)\n",
    "    \n",
    "    root = ET.fromstring(fetch_response.content)\n",
    "    \n",
    "    articles = []\n",
    "    for article in root.findall(\".//PubmedArticle\"):\n",
    "        pmid = article.find(\".//PMID\").text if article.find(\".//PMID\") is not None else \"ID not available\"\n",
    "        title_element = article.find(\".//ArticleTitle\")\n",
    "        title = title_element.text if title_element is not None else \"Title not available\"\n",
    "        abstract_element = article.find(\".//Abstract/AbstractText\")\n",
    "        abstract = abstract_element.text if abstract_element is not None else \"Abstract not available\"\n",
    "        doi_element = article.find(\".//ArticleId[@IdType='doi']\")\n",
    "        doi = doi_element.text if doi_element is not None else \"DOI not available\"\n",
    "        \n",
    "        articles.append({\n",
    "            'id': pmid,\n",
    "            'doi': doi,\n",
    "            'title': title,\n",
    "            'abstract': abstract\n",
    "        })\n",
    "    \n",
    "    return articles\n",
    "\n",
    "def preprocess_article(article):\n",
    "    # Check if the article is None\n",
    "    if article is None:\n",
    "        return None\n",
    "\n",
    "    # Check if 'abstract' key exists and is not None\n",
    "    if 'abstract' not in article or article['abstract'] is None:\n",
    "        return None\n",
    "\n",
    "    # Check if the abstract is too short or not available\n",
    "    if len(article['abstract']) < 50 or article['abstract'] == \"Abstract not available.\":\n",
    "        return None\n",
    "    \n",
    "    # Check if 'title' key exists and is not None\n",
    "    if 'title' not in article or article['title'] is None:\n",
    "        return None\n",
    "\n",
    "    # Check if the title is missing\n",
    "    if article['title'] == \"Title not available.\":\n",
    "        return None\n",
    "    \n",
    "    return article\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n",
    "def process_article_with_ollama(article, model_name=\"llama3\"):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    # Handle None abstract\n",
    "    abstract = article['abstract'] if article['abstract'] is not None else \"Abstract not available\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Analyze the following research article on assisted dying:\n",
    "\n",
    "Title: {article['title']}\n",
    "\n",
    "Abstract: {abstract}\n",
    "\n",
    "Please provide a detailed analysis addressing the following points. Format your response exactly as shown below:\n",
    "\n",
    "Study Type: [Empirical/Theoretical]\n",
    "\n",
    "Study Type Justification: [Your explanation here]\n",
    "\n",
    "Research Methods: [List only the specific research methods used, separated by commas. Use standard terminology such as Survey, Interview, Questionnaire, Observation, Experiment, Case Study, Literature Review, Meta-analysis, etc.]\n",
    "\n",
    "Research Methods Justification: [Your explanation here]\n",
    "\n",
    "Ensure your response follows this exact format for easy parsing.\n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()['response']\n",
    "        parsed_result = parse_llm_response(result)\n",
    "        \n",
    "        # Add article metadata to the parsed result\n",
    "        parsed_result['article_id'] = article['id']\n",
    "        parsed_result['doi'] = article['doi']\n",
    "        parsed_result['title'] = article['title']\n",
    "        parsed_result['abstract'] = abstract\n",
    "        \n",
    "        return parsed_result\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error processing article {article['id']}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def parse_llm_response(response):\n",
    "    parsed_result = {\n",
    "        'study_type': \"Unable to determine\",\n",
    "        'study_type_justification': \"Unable to determine\",\n",
    "        'research_methods': \"Unable to determine\",\n",
    "        'research_methods_justification': \"Unable to determine\"\n",
    "    }\n",
    "    \n",
    "    patterns = {\n",
    "        'study_type': r\"Study Type:\\s*(.+?)(?:\\n|$)\",\n",
    "        'study_type_justification': r\"Study Type Justification:\\s*(.+?)(?:\\n\\n|\\n[A-Z]|$)\",\n",
    "        'research_methods': r\"Research Methods:\\s*(.+?)(?:\\n|$)\",\n",
    "        'research_methods_justification': r\"Research Methods Justification:\\s*(.+?)(?:\\n\\n|$)\"\n",
    "    }\n",
    "    \n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            parsed_result[key] = match.group(1).strip()\n",
    "    \n",
    "    # Normalize research methods\n",
    "    if parsed_result['research_methods'] != \"Unable to determine\":\n",
    "        parsed_result['research_methods'] = normalize_research_methods(parsed_result['research_methods'])\n",
    "    \n",
    "    return parsed_result\n",
    "\n",
    "def validate_results(results):\n",
    "    validated_results = []\n",
    "    for result in results:\n",
    "        if all(value != \"Unable to determine\" for value in result.values()):\n",
    "            validated_results.append(result)\n",
    "        else:\n",
    "            print(f\"Incomplete result for article {result['article_id']}. Skipping.\")\n",
    "    return validated_results\n",
    "\n",
    "def save_results(results, base_filename):\n",
    "    # Save as JSON\n",
    "    json_filename = f\"{base_filename}.json\"\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"Results saved to {json_filename}\")\n",
    "\n",
    "    # Save as CSV\n",
    "    csv_filename = f\"{base_filename}.csv\"\n",
    "    \n",
    "    # Get all unique keys from all result dictionaries\n",
    "    fieldnames = set()\n",
    "    for result in results:\n",
    "        fieldnames.update(result.keys())\n",
    "    fieldnames = sorted(list(fieldnames))  # Sort field names for consistency\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for result in results:\n",
    "            writer.writerow(result)\n",
    "    print(f\"Results saved to {csv_filename}\")\n",
    "\n",
    "def run_integration_test(query=\"Assisted+dying\", max_articles=5, model_name=\"llama3\"):\n",
    "    print(f\"Running integration test with query: '{query}', max articles: {max_articles}, model: {model_name}\")\n",
    "    \n",
    "    # Fetch articles\n",
    "    articles = fetch_pubmed_articles(query, max_articles)\n",
    "    print(f\"Successfully fetched {len(articles)} articles.\")\n",
    "    \n",
    "    # Add this line to print the articles before processing\n",
    "    print(\"Articles before processing:\")\n",
    "    for article in articles:\n",
    "        print(f\"ID: {article['id']}, Title: {article['title'][:50]}...\")\n",
    "        if article['abstract'] is None:\n",
    "            print(f\"Warning: Article {article['id']} has no abstract.\")\n",
    "\n",
    "    # Process articles with Ollama\n",
    "    results = []\n",
    "    for i, article in enumerate(articles, 1):\n",
    "        print(f\"\\nProcessing article {i} of {len(articles)}...\")\n",
    "        try:\n",
    "            result = process_article_with_ollama(article, model_name)\n",
    "            results.append(result)\n",
    "            print(f\"Article ID: {result['article_id']}\")\n",
    "            print(f\"DOI: {result['doi']}\")\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"Abstract: {result['abstract'][:100]}...\")  # Truncated for display\n",
    "            print(f\"Study Type: {result['study_type']}\")\n",
    "            print(f\"Study Type Justification: {result['study_type_justification']}\")\n",
    "            print(f\"Research Methods: {result['research_methods']}\")\n",
    "            print(f\"Research Methods Justification: {result['research_methods_justification']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article {article['id']}: {str(e)}\")\n",
    "        print(\"-\" * 50)\n",
    "        time.sleep(1)  # Be respectful to the Ollama API\n",
    "    \n",
    "    print(f\"\\nIntegration test complete! Processed {len(results)} articles.\")\n",
    "    return results\n",
    "\n",
    "# Run the integration test\n",
    "if __name__ == \"__main__\":\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_filename = f\"pubmed_ollama_test_results_{timestamp}\"\n",
    "    \n",
    "    results = run_integration_test()\n",
    "    save_results(results, base_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
