{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3880 of 3880 articles\n",
      "\n",
      "Retrieved 3880 PMIDs for the keyword 'assisted dying'\n",
      "\n",
      "Created folder: pubmed_assisted_dying_20240822_121408\n",
      "Processed article 1 of 3880 (PMID: 39168589)\n",
      "Processed article 2 of 3880 (PMID: 39167528)\n",
      "Processed article 3 of 3880 (PMID: 39160544)\n",
      "Processed article 4 of 3880 (PMID: 39157533)\n",
      "Processed article 5 of 3880 (PMID: 39157418)\n",
      "Processed article 6 of 3880 (PMID: 39152645)\n",
      "Processed article 7 of 3880 (PMID: 39144136)\n",
      "Processed article 8 of 3880 (PMID: 39143961)\n",
      "Processed article 9 of 3880 (PMID: 39126283)\n",
      "Processed article 10 of 3880 (PMID: 39122437)\n",
      "Processed article 11 of 3880 (PMID: 39122386)\n",
      "Processed article 12 of 3880 (PMID: 39121499)\n",
      "Processed article 13 of 3880 (PMID: 39119216)\n",
      "Processed article 14 of 3880 (PMID: 39117361)\n",
      "Processed article 15 of 3880 (PMID: 39095146)\n",
      "Processed article 16 of 3880 (PMID: 39093520)\n",
      "Processed article 17 of 3880 (PMID: 39087246)\n",
      "Processed article 18 of 3880 (PMID: 39083816)\n",
      "Processed article 19 of 3880 (PMID: 39075491)\n",
      "Processed article 20 of 3880 (PMID: 39072234)\n",
      "Processed article 21 of 3880 (PMID: 39060645)\n",
      "Processed article 22 of 3880 (PMID: 39060033)\n",
      "Processed article 23 of 3880 (PMID: 39054766)\n",
      "Processed article 24 of 3880 (PMID: 39048142)\n",
      "Processed article 25 of 3880 (PMID: 39038989)\n",
      "Processed article 26 of 3880 (PMID: 39033579)\n",
      "Processed article 27 of 3880 (PMID: 39028317)\n",
      "Processed article 28 of 3880 (PMID: 39026237)\n",
      "Processed article 29 of 3880 (PMID: 39019922)\n",
      "Processed article 30 of 3880 (PMID: 39012365)\n",
      "Processed article 31 of 3880 (PMID: 38995203)\n",
      "Processed article 32 of 3880 (PMID: 38978832)\n",
      "Processed article 33 of 3880 (PMID: 38974806)\n",
      "Processed article 34 of 3880 (PMID: 38963252)\n",
      "Processed article 35 of 3880 (PMID: 38963249)\n",
      "Processed article 36 of 3880 (PMID: 38950570)\n",
      "Processed article 37 of 3880 (PMID: 38949456)\n",
      "Processed article 38 of 3880 (PMID: 38937089)\n",
      "Processed article 39 of 3880 (PMID: 38934930)\n",
      "Processed article 40 of 3880 (PMID: 38934811)\n",
      "Processed article 41 of 3880 (PMID: 38919634)\n",
      "Processed article 42 of 3880 (PMID: 38911274)\n",
      "Processed article 43 of 3880 (PMID: 38910003)\n",
      "Processed article 44 of 3880 (PMID: 38907636)\n",
      "Processed article 45 of 3880 (PMID: 38897835)\n",
      "Processed article 46 of 3880 (PMID: 38896003)\n",
      "Processed article 47 of 3880 (PMID: 38886985)\n",
      "Processed article 48 of 3880 (PMID: 38880708)\n",
      "Processed article 49 of 3880 (PMID: 38877494)\n",
      "Processed article 50 of 3880 (PMID: 38876926)\n",
      "Processed article 51 of 3880 (PMID: 38875484)\n",
      "Processed article 52 of 3880 (PMID: 38871403)\n",
      "Processed article 53 of 3880 (PMID: 38869817)\n",
      "Processed article 54 of 3880 (PMID: 38863565)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 174\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary plots: study_methods.png and study_types.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 164\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m         articles\u001b[38;5;241m.\u001b[39mappend(article_info)\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed article \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_pmids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (PMID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpmid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.34\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# To respect NCBI's rate limit\u001b[39;00m\n\u001b[1;32m    166\u001b[0m method_counts, type_counts \u001b[38;5;241m=\u001b[39m analyze_articles(articles)\n\u001b[1;32m    167\u001b[0m plot_results(method_counts, type_counts, save_folder)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def search_pubmed(query, retmax=100, retstart=0):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    search_url = f\"{base_url}esearch.fcgi?db=pubmed&term={query}&retmax={retmax}&retstart={retstart}&retmode=xml\"\n",
    "    response = requests.get(search_url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    \n",
    "    count = int(root.find(\".//Count\").text)\n",
    "    ids = [id_elem.text for id_elem in root.findall(\".//Id\")]\n",
    "    \n",
    "    return ids, count\n",
    "\n",
    "def fetch_full_text(pmid):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    fetch_url = f\"{base_url}efetch.fcgi?db=pubmed&id={pmid}&rettype=xml&retmode=xml\"\n",
    "    response = requests.get(fetch_url)\n",
    "    return response.text\n",
    "\n",
    "def get_all_articles(keyword):\n",
    "    retmax = 4000\n",
    "    retstart = 0\n",
    "    all_ids = []\n",
    "    \n",
    "    while True:\n",
    "        ids, total_count = search_pubmed(keyword, retmax, retstart)\n",
    "        all_ids.extend(ids)\n",
    "        \n",
    "        print(f\"Retrieved {len(all_ids)} of {total_count} articles\")\n",
    "        \n",
    "        if len(all_ids) >= total_count:\n",
    "            break\n",
    "        \n",
    "        retstart += retmax\n",
    "        time.sleep(0.34)  # To respect NCBI's rate limit of 3 requests per second\n",
    "    \n",
    "    return all_ids\n",
    "\n",
    "def create_folder(keyword):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    folder_name = f\"pubmed_{keyword.replace(' ', '_')}_{timestamp}\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    return folder_name\n",
    "\n",
    "def parse_xml(xml_string):\n",
    "    root = ET.fromstring(xml_string)\n",
    "    article = root.find(\".//PubmedArticle\")\n",
    "    \n",
    "    pmid = article.find(\".//PMID\").text\n",
    "    title = article.find(\".//ArticleTitle\").text\n",
    "    \n",
    "    abstract_element = article.find(\".//Abstract/AbstractText\")\n",
    "    abstract = abstract_element.text if abstract_element is not None else \"\"\n",
    "    \n",
    "    journal = article.find(\".//Journal/Title\").text\n",
    "    pub_date = article.find(\".//PubDate\")\n",
    "    year = pub_date.find(\"Year\").text if pub_date.find(\"Year\") is not None else \"N/A\"\n",
    "    \n",
    "    return {\n",
    "        \"PMID\": pmid,\n",
    "        \"Title\": title,\n",
    "        \"Abstract\": abstract,\n",
    "        \"Journal\": journal,\n",
    "        \"Year\": year\n",
    "    }\n",
    "\n",
    "def categorize_study(text):\n",
    "    method_keywords = {\n",
    "        'Survey': ['survey', 'questionnaire', 'interview'],\n",
    "        'Observational': ['cohort', 'case-control', 'cross-sectional', 'observational'],\n",
    "        'Experimental': ['randomized', 'controlled trial', 'intervention'],\n",
    "        'Review': ['systematic review', 'meta-analysis', 'literature review'],\n",
    "        'Qualitative': ['qualitative', 'focus group', 'ethnography', 'phenomenological'],\n",
    "        'Mixed Methods': ['mixed method', 'multi-method'],\n",
    "    }\n",
    "    \n",
    "    empirical_keywords = ['data', 'analysis', 'sample', 'participant', 'result', 'finding']\n",
    "    theoretical_keywords = ['framework', 'concept', 'theory', 'philosophical', 'ethics', 'moral']\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    methods = [method for method, keywords in method_keywords.items() \n",
    "               if any(keyword in text for keyword in keywords)]\n",
    "    \n",
    "    empirical_count = sum(keyword in text for keyword in empirical_keywords)\n",
    "    theoretical_count = sum(keyword in text for keyword in theoretical_keywords)\n",
    "    \n",
    "    study_type = 'Empirical' if empirical_count > theoretical_count else 'Theoretical'\n",
    "    \n",
    "    return methods, study_type\n",
    "\n",
    "def analyze_articles(articles):\n",
    "    method_counts = Counter()\n",
    "    type_counts = Counter()\n",
    "    \n",
    "    for article in articles:\n",
    "        text = f\"{article['Title']} {article['Abstract']}\"\n",
    "        methods, study_type = categorize_study(text)\n",
    "        \n",
    "        if methods:\n",
    "            method_counts.update(methods)\n",
    "        else:\n",
    "            method_counts['Unclassified'] += 1\n",
    "        \n",
    "        type_counts[study_type] += 1\n",
    "    \n",
    "    return method_counts, type_counts\n",
    "\n",
    "def plot_results(method_counts, type_counts, save_folder):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(method_counts.keys(), method_counts.values())\n",
    "    plt.title('Study Methods in Assisted Dying Research')\n",
    "    plt.xlabel('Method')\n",
    "    plt.ylabel('Number of Studies')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_folder, 'study_methods.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%')\n",
    "    plt.title('Empirical vs Theoretical Studies in Assisted Dying Research')\n",
    "    plt.savefig(os.path.join(save_folder, 'study_types.png'))\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    keyword = input(\"Enter the keyword to search for (e.g., 'assisted dying'): \")\n",
    "    all_pmids = get_all_articles(keyword)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(all_pmids)} PMIDs for the keyword '{keyword}'\")\n",
    "    \n",
    "    save_folder = create_folder(keyword)\n",
    "    print(f\"\\nCreated folder: {save_folder}\")\n",
    "    \n",
    "    csv_file_path = os.path.join(save_folder, \"articles_summary.csv\")\n",
    "    articles = []\n",
    "    \n",
    "    with open(csv_file_path, \"w\", newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = [\"PMID\", \"Title\", \"Abstract\", \"Journal\", \"Year\", \"Methods\", \"Study Type\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for i, pmid in enumerate(all_pmids, 1):\n",
    "            xml_content = fetch_full_text(pmid)\n",
    "            article_info = parse_xml(xml_content)\n",
    "            \n",
    "            text = f\"{article_info['Title']} {article_info['Abstract']}\"\n",
    "            methods, study_type = categorize_study(text)\n",
    "            \n",
    "            article_info['Methods'] = ', '.join(methods) if methods else 'Unclassified'\n",
    "            article_info['Study Type'] = study_type\n",
    "            \n",
    "            writer.writerow(article_info)\n",
    "            articles.append(article_info)\n",
    "            \n",
    "            print(f\"Processed article {i} of {len(all_pmids)} (PMID: {pmid})\")\n",
    "            time.sleep(0.34)  # To respect NCBI's rate limit\n",
    "    \n",
    "    method_counts, type_counts = analyze_articles(articles)\n",
    "    plot_results(method_counts, type_counts, save_folder)\n",
    "    \n",
    "    print(f\"\\nProcess completed. Results saved in folder: {save_folder}\")\n",
    "    print(f\"CSV file: {csv_file_path}\")\n",
    "    print(\"Summary plots: study_methods.png and study_types.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
